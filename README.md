# Awesome Self-Play with Large Language Models Papers

## Related Surveys
Game Theory Meets Large Language Models: A Systematic Survey
A Survey on Self-Play Methods in Reinforcement Learning

## Competitive

## Text-Based Games

<div style="margin-bottom: 1em;">
  <strong>Self-playing Adversarial Language Game Enhances LLM Reasoning</strong><br>
  <em>Cheng, Pengyu, Yong Dai, Tianhao Hu, Han Xu, Zhisong Zhang, Lei Han, Nan Du, and Xiaolong Li</em><br>
  NeurIPS 2024, <a href="https://arxiv.org/pdf/2404.10642v1">Paper</a>
</div>

<div style="margin-bottom: 1em;">
  <strong>Multi-agent KTO: Reinforcing Strategic Interactions of Large Language Model in Language Game</strong><br>
  <em>Ye, Rong, Yongxin Zhang, Yikai Zhang, Haoyu Kuang, Zhongyu Wei, and Peng Sun</em><br>
  arXiv 2025, <a href="https://arxiv.org/pdf/2501.14225">Paper</a>
</div>

<div style="margin-bottom: 1em;">
  <strong>STRATEGIST: Self-Improvement of LLM Decision Making via Bi-level Tree Search</strong><br>
  <em>Light, Jonathan, Min Cai, Weiqin Chen, Guanzhi Wang, Xiusi Chen, Wei Cheng, Yisong Yue, and Ziniu Hu</em><br>
  ICLR 2025, <a href="https://openreview.net/pdf?id=gfI9v7AbFg">Paper</a>
</div>

<div style="margin-bottom: 1em;">
  <strong>MARSHAL: Incentivizing Multi-Agent Reasoning via Self-Play with Strategic LLMs</strong><br>
  <em>Yuan, H., Xu, Z., Tan, Z., Yi, X., Guang, M., Long, K., Hui, H., Li, B., Chen, X., Zhao, B., and Zhang, X. P.</em><br>
  arXiv 2025, <a href="https://arxiv.org/pdf/2510.15414">Paper</a>
</div>

<div style="margin-bottom: 1em;">
  <strong>Enhancing Language Agent Strategic Reasoning through Self-Play in Adversarial Games</strong><br>
  <em>Zhang, Yikai, Ye Rong, Siyu Yuan, Jiangjie Chen, Jian Xie, and Yanghua Xiao</em><br>
  arXiv 2025, <a href="https://arxiv.org/pdf/2510.16761">Paper</a>
</div>

## Reasoning

<div style="margin-bottom: 1em;">
  <strong>Improving Rationality in the Reasoning Process of Language Models through Self-playing Game</strong><br>
  <a href="#">Paper</a>
</div>

<div style="margin-bottom: 1em;">
  <strong>Language Self-Play for Data-Free Training</strong><br>
  <em>Kuba, Jakub Grudzien, Mengting Gu, Qi Ma, Yuandong Tian, Vijai Mohan, and Jason Chen</em><br>
  arXiv 2025, <a href="https://arxiv.org/pdf/2509.07414">Paper</a>
</div>

<div style="margin-bottom: 1em;">
  <strong>SPICE: Self-Play in Corpus Environments Improves Reasoning</strong><br>
  <em>Liu, Bo, Chuanyang Jin, Seungone Kim, Weizhe Yuan, Wenting Zhao, Ilia Kulikov, Xian Li, Sainbayar Sukhbaatar, Jack Lanchantin, and Jason Weston</em><br>
  arXiv 2025, <a href="https://arxiv.org/pdf/2510.24684">Paper</a>
</div>

<div style="margin-bottom: 1em;">
  <strong>SPC: Evolving Self-Play Critic via Adversarial Games for LLM Reasoning</strong><br>
  <em>Chen, Jiaqi, Bang Zhang, Ruotian Ma, Peisong Wang, Xiaodan Liang, Zhaopeng Tu, Xiaolong Li, and Kwan-Yee K. Wong</em><br>
  arXiv 2025, <a href="https://arxiv.org/pdf/2504.19162">Paper</a>
</div>

<div style="margin-bottom: 1em;">
  <strong>War of Thoughts: Competition Stimulates Stronger Reasoning in Large Language Models</strong><br>
  <em>Chen, Yibin, Jinyi Liu, Yan Zheng, Yifu Yuan, and Jianye Hao</em><br>
  ACL 2025, <a href="https://aclanthology.org/2025.findings-acl.1118.pdf">Paper</a>
</div>
## Other

<div style="margin-bottom: 1em;">
  <strong>Digital Red Queen: Adversarial Program Evolution in Core War with LLMs</strong><br>
  <em>Kumar, Akarsh, Ryan Bahlous-Boldi, Prafull Sharma, Phillip Isola, Sebastian Risi, Yujin Tang, and David Ha</em><br>
  arXiv 2026, <a href="https://arxiv.org/pdf/2601.03335">Paper</a>
</div>

<div style="margin-bottom: 1em;">
  <strong>Incentivizing Truthful Language Models via Peer Elicitation Games</strong><br>
  <a href="#">Paper</a>
</div>

## Cooperative

<div style="margin-bottom: 1em;">
  <strong>Everyone Contributes! Incentivizing Strategic Cooperation in Multi-LLM Systems via Sequential Public Goods Games</strong><br>
  <em>Liang, Yunhao, Yuan Qu, Jingyuan Yang, Shaochong Lin, and Zuo-Jun Max Shen</em><br>
  arXiv 2025, <a href="https://arxiv.org/pdf/2508.02076">Paper</a>
</div>
